substitutions:
  # replace these values in Cloud Build UI
  _ORG_VIEWER_SA_EMAIL: '' # email of an existing Service Account with Org Viewer role
  _DNS_DOMAIN: '' # fully-resolved DNS domain name (e.g. appsec.example.org)
  _DNS_ZONE: '' # DNS zone name to be created/updated (e.g. appsec)

options:
  machineType: N1_HIGHCPU_8
  env:
  - PROJECT_ID=${PROJECT_ID}
  - BATCH_DISPATCHER_IMAGE=us.gcr.io/${PROJECT_ID}/batch-dispatcher:${SHORT_SHA}
  - BASTION_IMAGE=us.gcr.io/${PROJECT_ID}/bastion
  - CLOUDSQL_PROXY_IMAGE=us.gcr.io/${PROJECT_ID}/cloudsql-proxy:workaround
  - CIS_IMAGE=us.gcr.io/${PROJECT_ID}/cis
  - SOURCECLEAR_IMAGE=us.gcr.io/${PROJECT_ID}/sourceclear
  - CODEDX_ANALYSIS_IMAGE=us.gcr.io/${PROJECT_ID}/codedx-analysis:${SHORT_SHA}
  - DD_DJANGO_IMAGE=us.gcr.io/${PROJECT_ID}/defectdojo-django
  - DD_NGINX_IMAGE=us.gcr.io/${PROJECT_ID}/defectdojo-nginx
  - DOCS_IMAGE=us.gcr.io/${PROJECT_ID}/docs:${SHORT_SHA}
  - CODEDX_IMAGE=us.gcr.io/${PROJECT_ID}/codedx
  - SDARQ_FRONTEND_IMAGE=us.gcr.io/${PROJECT_ID}/sdarq-frontend:${SHORT_SHA}
  - SDARQ_BACKEND_IMAGE=us.gcr.io/${PROJECT_ID}/sdarq-backend:${SHORT_SHA}
  - CARTOGRAPHY_IMAGE=us.gcr.io/${PROJECT_ID}/cartography
  - DNS_DOMAIN=${_DNS_DOMAIN}
  - DNS_ZONE=${_DNS_ZONE}
  - TERRAFORM_BUCKET=${PROJECT_ID}-terraform
  - BROAD_INGRESS_CSP=broad-ingress
  - DISK_SNAPSHOT_POLICY=appsec-apps-disk-snapshot-policy
  - JOB_DISPATCHER_ROLE=job-dispatcher
  - GLOBAL_NAMESPACE=global
  - CIS_DATASET=cis
  - CODEDX_NAMESPACE=codedx
  - CODEDX_SERVICE=codedx
  - DOJO_NAMESPACE=defectdojo
  - DOJO_SERVICE=defectdojo
  - SDARQ_SERVICE_ACCOUNT=sdarq-sa
  - REGION=us-east1
  - ZONE_1=us-east1-b
  - ZONE_2=us-east1-c
  - KUBECTL_PROXY=kubectl-proxy

steps:
# prepare GCS backend for Terraform
- id: terraform-bucket
  name: gcr.io/cloud-builders/gsutil
  entrypoint: sh
  args:
  - -c
  - gsutil mb "gs://$${TERRAFORM_BUCKET}" ;
    gsutil versioning set on "gs://$${TERRAFORM_BUCKET}"

# Pre-pull Kaniko image, used to speed up Docker builds.
- id: kaniko
  name: &kaniko gcr.io/kaniko-project/executor:debug
  waitFor: ['-']
  entrypoint: 'true'

# build bastion proxy Docker image
- id: bastion-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/bastion
      --destination=$${BASTION_IMAGE}
      --cache

# deploy GKE cluster and associated GCP resources
- id: terraform
  name: hashicorp/terraform
  waitFor: ['terraform-bucket', 'bastion-image']
  entrypoint: sh
  dir: terraform
  args:
  - -c
  - terraform init
      -backend-config "bucket=$${TERRAFORM_BUCKET}" &&
    terraform plan -out=plan.out
      -var "project=${PROJECT_ID}"
      -var "region=$${REGION}"
      -var "zones=[\"$${ZONE_1}\",\"$${ZONE_2}\"]"
      -var "global_namespace=$${GLOBAL_NAMESPACE}"
      -var "bastion_image=$${BASTION_IMAGE}" &&
    terraform apply plan.out &&
    terraform output | tr -d " " > ../shared/.env

# set up proxy for GKE master
- id: kubectl-proxy
  name: gcr.io/cloud-builders/docker
  entrypoint: sh
  dir: shared
  args:
  - -c
  - export $(xargs < .env) &&
    docker run --net cloudbuild --name "$${KUBECTL_PROXY}" gcr.io/cloud-builders/gcloud compute
      start-iap-tunnel "${bastion_instance}" 1080 --local-host-port 0.0.0.0:8080 --zone "${bastion_zone}" &&
    sleep 5

# set up Config Connector and other shared GKE resources
- id: shared
  name: &kubectl gcr.io/cloud-builders/kubectl
  entrypoint: ./global.sh
  dir: shared

# workaround for instance metadata endpoint in CloudSQL proxy
- id: cloudsql-proxy
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/cloudsql-proxy
      --destination=$${CLOUDSQL_PROXY_IMAGE}
      --cache

# deploy Burp Enterprise to GKE cluster
- id: burp-enterprise
  name: *kubectl
  waitFor: ['shared']
  entrypoint: ./deploy.sh
  dir: burp-enterprise

# build Batch dispatcher image
- id: batch-dispatcher-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/batch
      --destination=$${BATCH_DISPATCHER_IMAGE}
      --cache

# build CIS Docker image
- id: cis-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/cis
      --destination=$${CIS_IMAGE}
      --cache

# deploy CIS scanner resources
- id: cis
  name: *kubectl
  waitFor: ['shared', 'batch-dispatcher-image', 'cis-image']
  entrypoint: ./deploy.sh
  dir: cis
  env:
  - GCP_SERVICE_ACCOUNT_EMAIL=${_ORG_VIEWER_SA_EMAIL}

# build patched DefectDojo Django image,
# using Kaniko to speed up builds
- id: defectdojo-django-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/defectdojo
      --dockerfile=Dockerfile.django
      --destination=$${DD_DJANGO_IMAGE}
      --cache

# build patched DefectDojo Nginx image
- id: defectdojo-nginx-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/defectdojo
      --dockerfile=Dockerfile.nginx
      --destination=$${DD_NGINX_IMAGE}
      --cache

# deploy DefectDojo to GKE cluster
- id: defectdojo
  name: *kubectl
  waitFor: ['shared', 'cloudsql-proxy', 'defectdojo-django-image', 'defectdojo-nginx-image']
  entrypoint: ./deploy.sh
  dir: defectdojo

# build patched CodeDx image
- id: codedx-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/codedx
      --destination=$${CODEDX_IMAGE}
      --cache

# deploy CodeDx to GKE cluster
- id: codedx
  name: *kubectl
  waitFor: ['shared', 'cloudsql-proxy', 'codedx-image']
  entrypoint: ./deploy.sh
  dir: codedx

# build SDARQ frontend Docker image
- id: sdarq-frontend-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/sdarq/frontend
      --destination=$${SDARQ_FRONTEND_IMAGE}
      --cache

# build SDARQ backend Docker image
- id: sdarq-backend-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/sdarq/backend
      --destination=$${SDARQ_BACKEND_IMAGE}
      --cache

# deploy SDARQ to GKE cluster
- id: sdarq
  name: *kubectl
  waitFor: ['shared', 'sdarq-frontend-image', 'sdarq-backend-image']
  entrypoint: ./deploy.sh
  dir: sdarq

# build Cartography Docker image
- id: cartography-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/secexplorer
      --destination=$${CARTOGRAPHY_IMAGE}
      --cache

# deploy SecExplorer to GKE cluster
- id: secexplorer
  name: *kubectl
  waitFor: ['shared', 'cartography-image']
  entrypoint: ./deploy.sh
  dir: secexplorer
  env:
  - GCP_SERVICE_ACCOUNT_EMAIL=${_ORG_VIEWER_SA_EMAIL}

# deploy Zap to GKE cluster
- id: zap
  name: *kubectl
  waitFor: ['shared', 'batch-dispatcher-image']
  entrypoint: ./deploy.sh
  dir: zap

# build codedx analysis Docker image
- id: codedx-analysis-image
  name: *kaniko
  waitFor: ['kaniko']
  entrypoint: sh
  args:
  - -c
  - executor
      --context=dir:///workspace/codedx-analysis
      --destination=$${CODEDX_ANALYSIS_IMAGE}
      --cache

# deploy codedx analysis to GKE cluster
- id: codedx-analysis-deployment
  name: *kubectl
  waitFor: ['shared', 'codedx-analysis-image']
  entrypoint: ./deploy.sh
  dir: codedx-analysis

timeout: 7200s
